import React, { useState, useRef } from 'react';
//Í∏∞Î≥∏Ï†ÅÏù∏ ÎÖπÏùå, Ï†ïÏßÄ, Îã§Ïö¥Î°úÎìú / Îã§Ïö¥Î°úÎìú ÏóÜÏù¥ Î∞îÎ°ú Ïû¨ÏÉù(ÌòÑÏû¨ Ìú¥ÎåÄÌè∞ÏóêÏÑú Ïû¨ÏÉùÏïàÎê®)
const AudioRecorder1 = () => {
    const [isRecording, setIsRecording] = useState(false);
    const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
    const [audioUrl, setAudioUrl] = useState<string | null>(null);
    const audioRef = useRef<HTMLAudioElement>(null); // Ïò§ÎîîÏò§ ÏóòÎ¶¨Î®ºÌä∏ Ï∞∏Ï°∞

    const startRecording = async () => {
        setIsRecording(true);
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const recorder = new MediaRecorder(stream);
        setMediaRecorder(recorder);

        const audioChunks: BlobPart[] = [];
        recorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
        };

        recorder.onstop = () => {
            setIsRecording(false);
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            const url = URL.createObjectURL(audioBlob);
            setAudioUrl(url);
        };

        recorder.start();
    };

    const stopRecording = () => {
        console.log('Current Recorder State:', mediaRecorder?.state);
        mediaRecorder?.stop();
        console.log('Recorder State after stop:', mediaRecorder?.state);
    };

    const downloadRecording = () => {
        if (audioUrl) {
            const link = document.createElement('a');
            link.href = audioUrl;
            link.download = 'recording.wav';
            link.click();
        }
    };

    const playRecording = () => {
        if (audioUrl && audioRef.current) {
            audioRef.current.src = audioUrl;
            audioRef.current.play();
        }
    };


    const requestMicrophoneAccess = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            // ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑ºÏù¥ ÌóàÏö©
            console.log('ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑º ÌóàÏö©Îê®', stream);
        } catch (error) {
            // ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑ºÏù¥ Í±∞Î∂Ä
            console.error('ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑º Í±∞Î∂ÄÎê® ÎòêÎäî ÏóêÎü¨ Î∞úÏÉù', error);
        }
    }
    requestMicrophoneAccess();


    const playAudioFile1 = () => {
        if (audioRef.current) {
            audioRef.current.src = '../audio/InMember.wav';
            audioRef.current.play();
        }
    };
    const playAudioFile2 = () => {
        if (audioRef.current) {
            audioRef.current.src = '../audio/InMember.mp3';
            audioRef.current.play();
        }
    };
    
    return (
        <div>
            <button onClick={startRecording} disabled={isRecording} style={{ backgroundColor: isRecording ? 'red' : 'green' }}>
                {isRecording ? 'Recording...' : 'Start Recording'}
            </button>
            <button onClick={stopRecording} disabled={!isRecording}>
                Stop Recording
            </button>
            <button onClick={downloadRecording}>
                Download Recording
            </button>
            <button onClick={playRecording} disabled={!audioUrl}>
                Play Recording
            </button>
            <button onClick={playAudioFile1}>
                Play Audio File(wav)
            </button>
            <button onClick={playAudioFile2}>
                Play Audio File(mp3)
            </button>
            {/* ÎÇòÎ®∏ÏßÄ Ïª¥Ìè¨ÎÑåÌä∏ ÎÇ¥Ïö© */}
            {isRecording && <div>üé§ ÎÖπÏùå Ï§ë...</div>}

            <audio ref={audioRef} controls style={{ display: 'block' }} />
        </div>
    );
};

export default AudioRecorder1;
